{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cae3ec1-379c-483c-824b-10e0d1a5c4da",
   "metadata": {},
   "source": [
    "##### Disclaimer: This project wasn't initially made to be flexible and so we did't define functions/classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373f23e-7f03-4cf0-908a-3738118dc211",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep Google Cloud Vision stuff\n",
    "Make sure you have the Vision API key in the same folder. Importing `os` allows us to work with environment variables. We set google cloud credentials to contents of `vision_key.json`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f94851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] ='vision_key.json'\n",
    "from google.cloud import vision\n",
    "vision_client = vision.ImageAnnotatorClient()\n",
    "image = vision.Image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96004bf1-ebd7-4698-9853-babfd8ca18af",
   "metadata": {},
   "source": [
    "### Extract text from images\n",
    "Prepare each page of readings `A` to `F` as a separate image with positive integer indexed file names. The set of images are then filed under folders `A` to `F`.<a name=\"cite_ref-1\"></a>[<sup>[1]</sup>](#cite_note-1) The images per reading are then extracted using `vision` methods and saved as strings under `pages`. Each set of pages are then saved to `references`. <a name=\"cite_ref-2\"></a>[<sup>[2]</sup>](#cite_note-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e075a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import io\n",
    "refnames = ['A','B','C','D','E','F']\n",
    "references = []\n",
    "for refname in refnames:\n",
    "    images = r'C:\\Users\\johns\\Documents\\GitHub\\image-text-extraction\\images'\n",
    "    images += '\\\\' + refname\n",
    "    \n",
    "    files = os.listdir(images) \n",
    "    image_count = 0\n",
    "    for image in files:\n",
    "        image_count += 1\n",
    "    \n",
    "    pages = []\n",
    "    for image in range(1,image_count+1):\n",
    "        image_path = r'C:\\Users\\johns\\Documents\\GitHub\\image-text-extraction\\images' \n",
    "        image_path += '\\\\' + refname + '\\\\' + str(image) + '.jpg'\n",
    "\n",
    "        with io.open(image_path, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "        image = vision.Image(content=content)\n",
    "\n",
    "        response = vision_client.text_detection(image=image)\n",
    "\n",
    "        text = response.text_annotations[0].description\n",
    "    \n",
    "        pages.append(text)\n",
    "    references.append(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bc780-f775-422c-bec0-3b2fbee3dee6",
   "metadata": {},
   "source": [
    "Here, we simply encode each reference as a single string. <a name=\"cite_ref-3\"></a>[<sup>[3]</sup>](#cite_note-3)\n",
    "\n",
    "<b>Note to self</b>: Don't run cell below because above code does not currently work due to expired billing. You will overwrite the presaved text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e609dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ref_final = []\n",
    "for ref in references:\n",
    "    oneString = ''\n",
    "    for page in ref:\n",
    "        oneString += page\n",
    "    ref_final.append(oneString)\n",
    "    \n",
    "for index in range(0,len(refnames)):\n",
    "    dirref = r'C:\\Users\\johns\\Documents\\GitHub\\image-text-extraction\\textfiles'\n",
    "    dirref += '\\\\' + refnames[index] + '.txt'\n",
    "    with open(dirref, 'w',encoding=\"utf-8\") as f:\n",
    "            f.write((ref_final[index]).replace(\"\\n\", \" \"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6511d9",
   "metadata": {},
   "source": [
    "### Comparing extracted files\n",
    "1. Encode strings to match in text file `keys.txt`. <a name=\"cite_ref-4\"></a>[<sup>[4]</sup>](#cite_note-4)\n",
    "2. Strip spaces when comparing strings (gets rid of possible hiccups).\n",
    "3. We will also not probably get an exact match since it's possible the professor encoded the letters differently (e.g. extra punctuations especially quotes and ellipsis), and so we take only fractions of strings <b>from the center</b> of each string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ab0d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we just use this for sorting the answers from first to last by order of keys\n",
    "def recsort(list1,length,list2=None):\n",
    "    if list2==None:\n",
    "        for index in range(0,length-1):\n",
    "            if list1[index] > list1[index+1]:\n",
    "                list1[index],list1[index+1] = list1[index+1],list1[index]\n",
    "        if length != 0:\n",
    "            recsort(list1,length-1)\n",
    "    elif len(list2)!=len(list1):\n",
    "        print(\"Invalid list lengths. Multiple lists should have the same length.\")\n",
    "        pass\n",
    "    else:\n",
    "        for index in range(0,length-1):\n",
    "            if list1[index] > list1[index+1]:\n",
    "                list1[index],list1[index+1] = list1[index+1],list1[index]\n",
    "                list2[index],list2[index+1] = list2[index+1],list2[index]\n",
    "        if length != 0:\n",
    "            recsort(list1,length-1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2151cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "refstrings = []\n",
    "\n",
    "for refname in refnames:\n",
    "    dirref = r'C:\\Users\\johns\\Documents\\GitHub\\image-text-extraction\\textfiles'\n",
    "    dirref += '\\\\' + refname + '.txt'\n",
    "    with open(dirref, 'r',encoding=\"utf-8\") as f:\n",
    "        refstrings.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae1eaf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: D\n",
      "2: F\n",
      "5: F\n",
      "6: E\n",
      "7: B\n",
      "8: B\n",
      "10: F\n",
      "11: E\n",
      "13: D\n",
      "15: E\n",
      "16: F\n",
      "17: F\n",
      "18: D\n",
      "19: E\n",
      "20: E\n",
      "21: F\n",
      "23: F\n",
      "24: F\n",
      "25: F\n",
      "26: E\n",
      "28: E\n",
      "30: F\n",
      "32: D\n",
      "34: E\n",
      "36: E\n",
      "38: F\n",
      "39: F\n",
      "40: B\n",
      "46: B\n",
      "49: E\n",
      "50: B\n",
      "53: E\n",
      "56: F\n",
      "57: F\n",
      "60: F\n",
      "62: B\n",
      "63: F\n",
      "64: B\n",
      "65: B\n",
      "66: F\n",
      "67: E\n",
      "68: F\n",
      "69: F\n",
      "73: F\n",
      "74: F\n",
      "75: F\n",
      "78: C\n",
      "79: F\n",
      "80: C\n",
      "82: F\n",
      "83: F\n",
      "Total:  60.0 %\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "with open(r'C:\\Users\\johns\\Documents\\GitHub\\image-text-extraction\\textfiles\\keys.txt', encoding = 'utf-8') as f:\n",
    "    for row in f:\n",
    "        keys.append(row)\n",
    "        \n",
    "import numpy as np\n",
    "\n",
    "#cleaning of strings\n",
    "new_refstrings = []\n",
    "for refstring in refstrings:\n",
    "    new_refstrings.append(refstring.replace(' ','').lower())\n",
    "new_keys = []\n",
    "for key in keys:\n",
    "    new_keys.append(key.replace(' ','').lower())\n",
    "    \n",
    "#comparing of strings; very makeshift heuristic solution by comparing inner text of strings\n",
    "tolerance = 0.2\n",
    "ref_count = 0\n",
    "answerkey,answerindex = [],[]\n",
    "for refstring in new_refstrings:\n",
    "    for index in range(0,len(keys)):\n",
    "        start = int(len(new_keys[index])/2 - (tolerance/2)*len(new_keys[index]))\n",
    "        last = int(len(new_keys[index])/2 + (tolerance/2)*len(new_keys[index]))\n",
    "        if new_keys[index][start:last] in refstring:\n",
    "            #print(new_keys[index][start:last]) #just useful for seeing how our key strings look\n",
    "            answerkey.append(refnames[ref_count])\n",
    "            answerindex.append(index+1)\n",
    "    ref_count += 1\n",
    "\n",
    "#just for sorting/beautifying answers\n",
    "recsort(answerindex,len(answerindex),answerkey)\n",
    "\n",
    "counter = 0\n",
    "for i in answerkey:\n",
    "    print(str(answerindex[counter])+\": \"+i)\n",
    "    counter += 1\n",
    "print(\"Total: \", (counter/85)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648c889-ba55-4647-b13a-0239386f7192",
   "metadata": {},
   "source": [
    "#### Footnotes:\n",
    "<a name=\"cite_note-1\"></a>[[1]](#cite_ref-1) Using absolute paths for file directories is VERY clunky, but the program tends to throw an error otherwise. Decided not to figure this out.<br>\n",
    "<a name=\"cite_note-2\"></a>[[2]](#cite_ref-2) Cell currently throws the error `PermissionDenied: 403 This API method requires billing to be enabled.` because of my expired billing account. <br>\n",
    "<a name=\"cite_note-3\"></a>[[3]](#cite_ref-3) Just because it's easier to think about. Might also help speedup the process (?) since there's only a single string file to work with. <br>\n",
    "<a name=\"cite_note-4\"></a>[[4]](#cite_ref-4) I did this manually..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706efb1-d3d7-4979-ab5a-3fafdbde3362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c5c9b07867e23e0e1c2a42e1a235cae4a285ff524e1cc5576f317d92fe78880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
